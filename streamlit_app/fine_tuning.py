import streamlit as st
import pandas as pd
import pickle
import plotly.graph_objects as go
from graph_model_F import plot_auc, plot_f1_score, plot_loss_curve , plot_precision_curve

with open(r"C:\Users\Gamy\Documents\GitHub\FEV24_BDS_Radios_Pulmonaire\models\history_DenseNet201_finetuned.pkl", "rb") as file1:
    history_densenet = pickle.load(file1)
with open(r"C:\Users\Gamy\Documents\GitHub\FEV24_BDS_Radios_Pulmonaire\models\history_VGG16.pkl", "rb") as file2:
    history_vgg = pickle.load(file2)

def show_fine_tuning():

    tab1, tab2, tab3, tab4 = st.tabs(["üõ†Ô∏è Preprocessing", "üìà Benchmarks", "üíª Mod√®les test√©s", "ü§ñ Mod√®le final"])
    
    st.markdown("""
    <style>
        .stTabs [data-baseweb = "tab-list"] {
            gap: 5px;
        }
        .stTabs [data-baseweb = "tab"] {
            height: 25px;
            white-space: pre-wrap;
            background-color: #626C66;
            border-radius: 4px 4px 0px 0px;
            border: 1px solid #fff;
            gap: 5px;
            padding-top: 10px;
            padding-bottom: 10px;
            padding-right: 5px;
        }
        .stTabs [aria-selected = "true"] {
            background-color: #F4FFFD;
            border : 1px solid #626C66;
        }
    </style>""", unsafe_allow_html = True)
    
    ### Premier onglet
    with tab1:
        st.header("Preprocessing des images")
        st.markdown('''
            Une √©tape tr√®s importante de notre projet est l'attention port√©e au traitement des images d'entr√©e. Nous avons pu voir pr√©c√©demment que les images poss√®dent pour certaines, des dimensions et/ou un nombre de canaux diff√©rents. Il est important d'homog√©n√©iser l'ensemble des param√®tres de nos images pour assurer une bonne performance de nos mod√®les, et surtout, des r√©sultats comparables. Les √©l√©ments en question sont :
            - Une dimension homog√®ne et carr√©e, par d√©faut 256x256 pixels.
            - Un nombre de trois canaux de couleur.
            - Une normalisation de la valeur des pixels.\n
            Une fonction `preproc_img()` est con√ßue pour simplifier ces √©tapes, am√©liorer la reproductibilit√© et faciliter les ajustements. Elle retourne automatiquement les **ensembles d'entra√Ænement et de test**.
        ''')

        # Style CSS pour listes √† puces internes
        st.markdown('''
        <style>
        [data-testid="stMarkdownContainer"] ul{
            list-style-position: inside;
        }
        </style>
        ''', unsafe_allow_html = True)

        # D√©finir le code comme une cha√Æne de caract√®res longue
        code = """
                def preproc_img(df_images, df_masks, n_img, normalize, files_path, resolution, with_masks):
                    np.random.seed(42)
                    # Gestion des erreurs
                    if resolution[2] != 1 and resolution[2] != 3:
                        return print("Le nombre de canaux doit √™tre de 1 (en nuances de gris) ou de 3 (en couleur)")

                    if resolution[0] != resolution[1]:
                        return print("La largeur de l'image doit √™tre la m√™me que sa hauteur.")
                    
                    if normalize != 'imagenet' and normalize != 'simple':
                        print(Attention : aucune normalisation n'a √©t√© appliqu√©e. Utilisez 'imagenet' pour une normalisation standardis√©e selon le mode op√©ratoire du set ImageNet ou 'simple' pour simplement normaliser la valeur des canaux entre 0 et 1.")

                    df_images_selected_list = []
                    for label, group in df_images.groupby('LABEL'):
                        n_samples = min(len(group), n_img)
                        df_images_selected_list.append(group.sample(n=n_samples, replace=False))
                    df_images_selected = pd.concat(df_images_selected_list)

                    images = []  # Initialiser une liste pour stocker les images pr√©trait√©es
                    df_masks_selected = df_masks[df_masks['FILE_NAME'].isin(df_images_selected['FILE_NAME'])] if with_masks else None

                    for i in range(len(df_images_selected)):
                        img_path = df_images_selected[files_path].iloc[i]
                        mask_path = df_masks_selected[files_path].iloc[i] if with_masks else None

                        img = Image.open(img_path)  # Charger l'image avec PIL
                        img = img.convert("L") if resolution[2] == 1 else img.convert("RGB")

                        img_resized = img.resize((resolution[0], resolution[1]))

                        # Normalisation des valeurs des pixels
                        if normalize == 'imagenet':
                            img_normalized = np.array(img_resized) / 255.0
                            img_normalized -= np.array([0.485, 0.456, 0.406]) if resolution[2] == 3 else np.mean([0.485, 0.456, 0.406])
                            img_normalized /= np.array([0.229, 0.224, 0.225]) if resolution[2] == 3 else np.mean([0.229, 0.224, 0.225])
                        elif normalize == 'simple':
                            img_normalized = img_resized / 255
                        else:
                            img_normalized = img_resized

                        images.append(img_normalized)

                    data = np.array(images).reshape(-1, resolution[0], resolution[1], resolution[2])
                    target = df_images_selected['LABEL']
                    return data, target
                """

        with st.expander("Voir le code de la fonction preproc_img()"):
            st.code(code, language = 'python')
    
        st.markdown('''Le processus de pr√©traitement des donn√©es consiste √† uniformiser les donn√©es en les important via `OpenCV` avec `cv2.IMREAD_GRAYSCALE` et en les convertissant en uint8 pour √©conomiser de la m√©moire. 
                       Les images peuvent √™tre redimensionn√©es √† la r√©solution de notre choix, stock√©es sous forme d'arrays numpy. 
                       Une normalisation de l'intensit√© des pixels peut √™tre appliqu√©e selon les besoins et les attentes des mod√®les, et des m√©thodes d'√©quilibrage des classes comme l'undersampling ou l'oversampling peuvent √™tre envisag√©es en raison de diff√©rences significatives dans leur r√©partition. 
                       Les premiers masques sont utilis√©s pour limiter la surface aux informations utiles, avec la possibilit√© de cr√©er de nouveaux masques.
                    ''')
        st.markdown(''' Derni√®re √©tape apr√®s nos images propres et normalis√©es, il est n√©cessaire de transformer nos labels multiclasses en entiers afin d'assurer la compatibilit√© avec une les mod√®les de classificiation.
                        Cette √©tape n√©cessite seulement un traitement par **One Hot Encoding** gr√¢ce √† `LabelEncoder()`.
                    ''')
        
        data = {
            'Classes': ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia'],
            'Num√©ros correspondants': [0, 1, 2, 3]
        }
        df = pd.DataFrame(data)

        # Convertir le dataframe en HTML avec les styles CSS
        html_table = df.to_html(index=False, justify='center', classes='styled-table')

        # Afficher le HTML dans Streamlit avec la largeur calcul√©e
        st.markdown(f"<div style='border: 1px solid white; border-radius: 5px; padding: 10px; background-color: #343434; line-height: 1; width: 350px; margin: 0 auto;'>{html_table}</div>", unsafe_allow_html=True)
    
    ### Deuxi√®me onglet
    with tab2:
            df = pd.read_csv(r"df_file\Lenet_nb_image.csv")
            df2 = pd.read_csv(r"df_file\Lenet_nb_epoque.csv") 


            col1, col2 = st.columns(2)

            with col1 :

                fig = go.Figure()

                fig.add_trace(go.Scatter(x=df['nombre_images'], y=df['Precision max'], mode='lines+markers', name='Precision max', line=dict(color='lightblue')))
                fig.add_trace(go.Scatter(x=df['nombre_images'], y=df['Precision max validation'], mode='lines+markers', name='Precision max validation', line=dict(color='salmon')))

                fig.add_vline(x=1325, line=dict(color='red', width=1, dash='dash'))
                fig.update_layout(title="Evolution de la pr√©cision max en fonction du nombre d'image",
                                xaxis_title='Nombre d\'images',
                                yaxis_title='Pr√©cision max',
                                template='plotly_white',
                                paper_bgcolor='rgba(0,0,0,0)',
                                plot_bgcolor='rgba(0,0,0,0)',
                                legend=dict(font=dict(color='white')),
                                xaxis=dict(tickfont=dict(color='white')),
                                yaxis=dict(tickfont=dict(color='white')),
                                title_font=dict(color='white'))
                st.plotly_chart(fig)

            with col2: 

                fig2 = go.Figure()

                fig2.add_trace(go.Scatter(x=df2['Nombre epoque'], y=df2['Precision max'], mode='lines+markers', name='Precision max', line=dict(color='lightblue')))
                fig2.add_trace(go.Scatter(x=df2['Nombre epoque'], y=df2['Precision max validation'], mode='lines+markers', name='Precision max validation', line=dict(color='salmon')))

                fig2.update_layout(title="Evolution de la pr√©cision max en fonction du nombre d'√©poque",
                                xaxis_title='Nombre d\'√©poque',
                                yaxis_title='Pr√©cision max',
                                template='plotly_white',
                                paper_bgcolor='rgba(0,0,0,0)',
                                plot_bgcolor='rgba(0,0,0,0)',
                                legend=dict(font=dict(color='white')),
                                xaxis=dict(tickfont=dict(color='white')),
                                yaxis=dict(tickfont=dict(color='white')),
                                title_font=dict(color='white'))

                st.plotly_chart(fig2)

    ### Troisi√®me onglet
    with tab3:
            Slider = st.select_slider(" ", options = ["Transfer learning" , "Fine Tuning"])

            categorie = {"Transfer learning" :["Mod√®les test√©s","InceptionResNetV2","ResNet121V2","DenseNet201","VGG16", "VGG19","ConvNextTiny","ConvNextBase","EfficientNet B4"],
                        "Fine Tuning" : ["EfficientNet", "ResNet", "VGG16_ft" ,"DenseNet"]}

            Choice_cr = st.selectbox("Navigation",
                                    options = categorie[Slider])
            
            csv_path_cr = {"Mod√®les test√©s" :r"df_file\df test model.csv",
                        "InceptionResNetV2" :r"df_file\df InceptionRes.csv",
                        "ResNet121V2" : r"df_file\df Res.csv",
                        "DenseNet201": r"df_file\df densenet.csv",
                        "VGG16" : r"df_file\df VGG16.csv", 
                        "VGG19" : r"df_file\df VGG19.csv",
                        "ConvNextTiny" : r"df_file\df Convtiny.csv",
                        "ConvNextBase" : r"df_file\df Convbase.csv",
                        "EfficientNet B4" :r"df_file\df efficient.csv",
                        "EfficientNet" :r"df_file\df efficientnet finetuned.csv",
                        "ResNet" :r"df_file\df resnet finetuned.csv",
                        "VGG16_ft" :r"df_file\df VGG16_finetuned.csv",
                        "DenseNet" :r"df_file\df densenet_finetuned.csv"}
            
            comm_dico = {"Mod√®les test√©s" :""" Voici un r√©capitulatif des mod√®les que nous avons test√© dans le cadre du transfer learning. """,
                        "InceptionResNetV2" :""" Le mod√®le a une capacit√© variable √† distinguer les diff√©rentes classes de radiographies. La classe Viral Pneumonia pr√©sente d'excellents scores de pr√©cision, de rappel et de F1, indiquant une identification quasi parfaite, tandis que la classe Normal a montr√© des difficult√©s plus marqu√©es, avec les scores les plus bas pour ces m√™mes m√©triques. Le score F1, qui √©quilibre la pr√©cision et le rappel, sugg√®re que le mod√®le est plus apte √† identifier correctement les classes COVID et Viral Pneumonia, __mais qu'il pourrait b√©n√©ficier d'un r√©√©quilibrage ou d'un ajustement dans la classification des classes Lung_Opacity et Normal.__ """ ,
                        "ResNet121V2" :""" Le mod√®le a une certaine tendance √† confondre la classe COVID avec les classes Lung_Opacity et Normal, comme en t√©moignent les 11 erreurs dans chaque cas. N√©anmoins, la classe Viral Pneumonia est interpr√©t√©e avec une grande pr√©cision, indiquant que les caract√©ristiques distinctives de cette classe sont bien captur√©es par le mod√®le. Les m√©triques par classe montrent que la classe 3 se distingue avec une pr√©cision et un rappel exceptionnels proches de 0.98, menant √† un score F1 similaire, qui est une mesure robuste de la pr√©cision globale. Les classes COVID, Lung_Opacity, et Normal pr√©sentent des scores F1 l√©g√®rement plus bas, mais toujours respectables, bien que ces classes pourraient b√©n√©ficier d'un r√©ajustement du mod√®le pour am√©liorer la distinction entre elles. __La pr√©cision globale du mod√®le √† 0.88 est solide, mais l'objectif serait de viser une am√©lioration dans la classification fine entre les classes similaires.__""" ,
                        "DenseNet201":"""  Les erreurs de classification les plus courantes semblent se produire entre les classes Lung_Opacity et Normal, sous-entendant des similarit√©s entre les caract√©ristiques des radiographies que le mod√®le confond certainement. Selon le tableau de m√©triques, le mod√®le a une excellente pr√©cision pour la classe COVID et des scores exceptionnels de rappel et de F1 pour la classe Viral Pneumonia, indiquant une classification presque parfaite pour ces cat√©gories. Les classes Lung_Opacity et Normal ont des scores F1 l√©g√®rement inf√©rieurs mais comparables. __Tout ceci indique une bonne performance de classification qui reste uniforme entre ces cat√©gories.__""" ,
                        "VGG16" : """ Le mod√®le parvient √† tr√®s bien classer les radiographies des classes Viral (Viral pneumonia) et COVID. √âgalement, m√™me si les r√©sultats restent bons, le mod√®le commet plus d'erreurs de classification entre les cat√©gories Normal et Lung (Lung_opacity). __Sans ajustement particulier, ce mod√®le semble d√©j√† prometteur quant √† ses capacit√©s √† classifier nos radiographies correctement.__""", 
                        "VGG19" : """ Les r√©sultats obtenus semblent √©galement tr√®s bons et superposables  √† ceux que nous avons obtenus pour que pour VGG16. __Cependant ce mod√®le √©tant un peu plus profond, il demande des ressources computationnelles plus importantes sans que cela ne se r√©percute de fa√ßon √©vidente sur ses performances.__ """,
                        "ConvNextTiny" : """ Avec ce mod√®le il appara√Æt que la classification est significativement meilleure pour la cat√©gorie  Viral (Viral pneumonia) que pour les autres. Ceci donne un score global en de√ß√† de ce que nous avons pu observer sur d‚Äôautres mod√®les dans les m√™mes conditions de test. Les courbes d‚Äôapprentissage sugg√®rent que le mod√®le pourrait b√©n√©ficier d‚Äôun nombre d'√©poques sup√©rieur pour continuer √† s‚Äôam√©liorer. """,
                        "ConvNextBase" : """ La classe Viral pneumonia reste toujours la mieux d√©tect√©e, suivie de la classe COVID. Les r√©sultats obtenus ici sont donc comparables √† ceux obtenus avec le mod√®le ConvNeXtTiny. Encore une fois le mod√®le semble pouvoir b√©n√©ficier d‚Äôun allongement de la dur√©e d'entra√Ænement. Cependant il est √† noter que ce mod√®le peut se montrer gourmand en termes de ressource computationnelle, __une √©poque de ConvNeXtBase pouvant prendre entre deux et trois fois plus de temps que le mod√®le ConvNeXtTiny sans montrer une diff√©rence flagrante de performance.__""",
                        "EfficientNet B4" :"""La pr√©cision du mod√®le chute √† 0.88 sur l‚Äôensemble test. La d√©tection de la classe COVID n'est pas au niveau de ce que l‚Äôon esp√©rait avec une pr√©cision de 0.91. __Globalement, le mod√®le avec ce param√©trage donne de bons r√©sultats.__ Dans la section suivante, nous allons essayer un ajustement plus fin pour avoir de  meilleures performances avec ce mod√®le. """,
                        "EfficientNet" :""" __Avec une pr√©cision globale de 0.94, c‚Äôest le meilleur mod√®le que nous avons eu pour cette partie concernant la famille de mod√®les EfficientNet.__ De plus, le mod√®le semble bien plus performant concernant la classe qui nous int√©resse ici (classe COVID), avec une reconnaissance des radiographies COVID √† 0.98 avec pr√©cision. Pour la suite de nos travaux, le meilleur mod√®le sera adopt√© et utilis√© pour l‚Äôinterpr√©tabilit√© et la suite de cette √©tude.""",
                        "ResNet" :""" Bien que performant, le mod√®le tend √† √™tre frein√© dans ses performances par la classe Lung_Opacity, dans laquelle il classe des poumons sains et vice-versa. Quelques poumons sains sont aussi incorrectement class√©s en Viral Pneumonia. __Ce mod√®le est donc performant, et supprimer la classe Lung_Opacity b√©n√©ficierait certainement beaucoup au InceptionResNetV2.__""",
                        "VGG16_ft" :""" Le mod√®le a donc √©t√© entra√Æn√© avec ces param√®tres ce qui nous permet d‚Äôam√©liorer encore l‚Äôefficacit√© du mod√®le par rapport √† ce que nous avions obtenu sans finetuning. Les classes les mieux pr√©dites sont COVID et Viral (Viral pneumonia), suivies par les classes Lung Opacity et Normal. De fa√ßon int√©ressante , toutes nos m√©triques sont au-dessus de 90% et suite √† l'entra√Ænement du mod√®le avec les meilleurs param√®tres nous obtenons une accuracy globale de 95%. __Ce mod√®le semble donc capable de fournir des r√©sultats plus qu‚Äôacceptables tout en ayant un co√ªt computationnel tr√®s contenu.__""",
                        "DenseNet" :""" Le rapport de classification montre des valeurs √©lev√©es pour la pr√©cision, le rappel et le F1 Score pour chaque classe ce qui indique que le mod√®le est particuli√®rement performant dans la distinction entre les diff√©rentes conditions. A noter cependant qu‚Äôil performe tout particuli√®rement dans la distinction de la classe COVID et de la classe Viral Pneumonia mais est un peu moins efficace dans la d√©tection des classes Normal et Lung_Opacity. Pour le COVID, le mod√®le a tr√®s bien perform√©, avec seulement 3 faux positifs et faux n√©gatifs. Les r√©sultats pour les autres conditions sont √©galement bons, mais on note quelques erreurs, par exemple, 23 cas de Lung_Opacity ont √©t√© confondus avec la classe Normal. __N√©anmoins, ces erreurs semblent √™tre faibles en comparaison avec le nombre total de pr√©dictions correctes.__"""}


            df = pd.read_csv(csv_path_cr[Choice_cr])
            df= df.fillna("")

            # Convertir le dataframe en HTML avec les styles CSS
            html_table = df.to_html(index=False, justify='center', classes='styled-table')

            # D√©finir le style CSS pour centrer l'affichage du DataFrame et le fond
            css_style = """
            <style>
                .background-div {
                    max-width: fit-content; /* Largeur adapt√©e au contenu */
                    margin: 0 auto; /* Centrer horizontalement */
                    padding: 10px;
                    background-color: #343434;
                    border-radius: 5px;
                }
                .inner-div {
                    text-align: center; /* Centrer le contenu */
                }
            </style>
            """

            # Ajouter le style CSS √† la balise div
            styled_html_table = f"<div class='background-div'><div class='inner-div'>{html_table}</div></div>"

            col1, col2 = st.columns(2)

            with col1 :

                st.markdown(css_style, unsafe_allow_html=True)
                st.markdown(styled_html_table, unsafe_allow_html=True)
            
            with col2 :
                 
                st.markdown(comm_dico[Choice_cr])


    ### Quatri√®me onglet
    with tab4:

        model_f = st.selectbox ('Meilleurs mod√®les', options = ["VGG16" , "DenseNet"] ) 

        path_pickle = {"VGG16" : r"pickle_file\model_historyVGG16BP_test.pkl",
                    "DenseNet" : r"pickle_file\history_DenseNet201_finetuned_0_95_20epochs.pkl"}
        
        best_hp = {"VGG16" : """ 
                   - Derni√®re couche dense : 1024 neurones
                   - Dropout : 0
                   - Learningrate : 10e-4 """,
                   "DenseNet" : """ 
                    - Derni√®re couche dense : 256 neurones (Regularisation L2 : 0.01)
                    - Dropout : 0.4,
                    - Learning rate : 10e-4 """}
        
        with open(path_pickle[model_f], 'rb') as fichier:
        # Charger les donn√©es √† partir du fichier
            history = pickle.load(fichier)
        
    Col1 , Col2 = st.columns(2)

    with Col1:
        plot_loss_curve(history)
        plot_auc(history)
    
    with Col2:
        plot_precision_curve(history)
        plot_f1_score(history)

    st.markdown(best_hp[model_f])
